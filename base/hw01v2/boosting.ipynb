{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами, если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: В каком пространстве градиентный бустинг совершает градиентный спуск? Какова размерность этого пространства?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 2**: Почему бустинг над глубокими деревьями это плохая идея?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 3**: Что предсказывает каждое дерево (что является признаками а что целевой переменной?)\n",
    "\n",
    "<Ответ>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Binary Boosting Implementation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вспомним бустинг\n",
    "\n",
    "#### Градиентный спуск\n",
    "\n",
    "Самый простой метод минимизации функции, для оптимизации в каждый момент времени двигаемся по антиградиенту функции с каким-то шагом. \n",
    "\n",
    "$$w_{n+1} = w_n - s \\cdot \\frac{\\partial f}{\\partial w}$$\n",
    "\n",
    "#### Градиентный бустинг\n",
    "\n",
    "Теперь давайте представим, что на каждом шаге мы оптимизируем не параметры алгоритма $w$, а ответы нашего алгоритма $\\hat{y}$.\n",
    "\n",
    "**Обучение**: На каждом шаге, давайте предсказывать градиент на каждом объекте и \"двигать\" ответ в сторону улучшения (антиградиента).\n",
    "\n",
    "**Алгоритм**:\n",
    "- Первый алгоритм отвечает константу \n",
    "- Добавляем базовые алгоритмы $b_i$, $i = 1, .., N$:\n",
    "    - $\\hat{y} = \\sum_{j=0}^{i-1} a_j b_j(x)$\n",
    "    - Вычисляем градиент функции потерь ПО ОТВЕТАМ модели $g_{i-1} = \\frac{\\partial L(\\hat{y},~~y)}{\\partial \\hat{y}}$ на каждом объекте  \n",
    "    - Обучаем $b_i$ предсказывать текущий $g_{i-1}$ (Тут дерево не глубокое регрессионное дерево)\n",
    "    - Дополняем композицию $\\sum_{j=0}^{i-1} a_j b_j (x) + lr * b_i(x)$\n",
    "    \n",
    "    \n",
    "#### Нужно реализовать двух классовый бустинг с логистической функцией потерь.     \n",
    "\n",
    "**Функция потерь**:\n",
    "Я вот думаю, что всем интересно какую-же функцию потерь выбрать $\\mathcal{L}(\\hat{y},y)=\\log\\left( 1 + e^{-\\hat{y}y} \\right)$\n",
    "\n",
    "тут важный момент есть, даже не один\n",
    "- $\\hat{y}$ -- это ответ композиции, тоесть сумма ответов всех предыдущих деревьев\n",
    "- Это скалярная функция и производная халява, но вот тут мы вам посчитали $$\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} = \\frac{1}{1 + e^{-y\\hat{y}}} \\cdot (-ye^{-y\\hat{y}})=-y\\frac{1}{1 + e^{y\\hat{y}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from utils import plot_surface\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BinaryBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators, lr=0.1):\n",
    "        self.lr = lr   \n",
    "        self.n_estimators = n_estimators\n",
    "    \n",
    "    def loss_grad(self, original_y, pred_y):\n",
    "        # Функция должна вернуть вектор длины = len(pred_y)\n",
    "        # В каждом элементе вектора должно быть значение градиента dL(pred_y, original_y) / d pred_y[i]\n",
    "        return # Градиент на каждом объекте\n",
    "        \n",
    "    def fit(self, X, original_y):\n",
    "        # Храните базовые алгоритмы тут\n",
    "        self.estimators_ = [] \n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            grad = self.loss_grad(original_y, self._predict(X))\n",
    "            # Настройте базовый алгоритм на градиент, это классификация или регрессия?\n",
    "            estimator = <Тут Ваш код>\n",
    "            self.estimators_.append(estimator)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X):\n",
    "        # Эта штука как раз должна вернуть сумму ответов всех алгоритмов \n",
    "        # Не забудьте про ленинг рейт\n",
    "        y_pred = <Получите ответ композиции до применения решающего правила>\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # А тут на выходе должны быть классы, подумайте как это сделать\n",
    "        y_pred = <примените к self._predict решающее правило>\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Simple test</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2,\n",
    "                           n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.05, class_sep=0.8, random_state=241)\n",
    "y = 2*(y-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BinaryBoostingClassifier(n_estimators=100).fit(X, y)\n",
    "plot_surface(X, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Adult test</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Скачайте https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\n",
    "    './data/adult.data', \n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"], \n",
    "    header=None, na_values=\"?\")\n",
    "adult = pd.get_dummies(adult)\n",
    "adult[\"Target\"] = adult[\"Target_ >50K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "y = 2*(y-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "<Сверьте качество своего алгоритма с GradientBoostingClassifier, оно должно быть примерно таким-же>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Сдача ДЗ</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполните форму https://goo.gl/forms/sPE6gpRDNTOXQai12 \n",
    "    - Качество вашего алгоритма на adult, один знак после запятой, без округления (0.86 -> 0.8 и тд) точность\n",
    "    - BinaryBoostingClassifier.loss_grad ([-1, 1, 1], [-1, 1, -1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
